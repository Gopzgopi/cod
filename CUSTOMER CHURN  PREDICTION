import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score
import joblib
import os

# Load dataset
data_path = "/kaggle/input/bank-customer-churn-prediction/Churn_Modelling.csv"  # Use your actual dataset path
df = pd.read_csv(data_path)


# Drop unnecessary columns (assuming these aren't needed)
df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)

# Encode categorical variables
label_encoders = {}
for col in ['Geography', 'Gender']:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Splitting data into features and target
X = df.drop(columns=['Exited'])
y = df['Exited']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardizing features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train model
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Model Accuracy: {accuracy:.4f}')

# Define Kaggle output directory
output_dir = "/kaggle/working/"
os.makedirs(output_dir, exist_ok=True)

# Save model and scaler
model_path = os.path.join(output_dir, "model.pkl")
scaler_path = os.path.join(output_dir, "scaler.pkl")

joblib.dump(model, model_path)
joblib.dump(scaler, scaler_path)

# Print Kaggle output command
print("kaggle kernels output gopikad/CUSTOMER CHURN PREDICTION/kaggle/working/")
Model Accuracy: 0.8150
kaggle kernels output gopikad/CUSTOMER CHURN PREDICTION/kaggle/working/
